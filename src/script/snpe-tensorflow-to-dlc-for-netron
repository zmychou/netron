#!/usr/bin/env python
#=============================================================================
#
#  Copyright (c) 2015-2016,2018 Qualcomm Technologies, Inc.
#  All Rights Reserved.
#  Confidential and Proprietary - Qualcomm Technologies, Inc.
#
#=============================================================================

import argparse
import logging
import os
import sys
import traceback

import tensorflow as tf
try:
    from snpe.converters.tensorflow.loader import ModelLoader
    from collections import OrderedDict
    import snpe.dlc_utils

    import snpe.converters.common.utils.code_to_message as code_to_message
    import snpe.converters.tensorflow.layers as layers
    from snpe.converters.tensorflow.layers.ignored_patterns import IgnoredLayersResolver
    from snpe.converters.tensorflow.common import InputLayerDescriptor
    from snpe.converters.tensorflow.util import (
        ConverterError,
        GraphHelper,
        uniques
    )
    from snpe.converters.tensorflow.graph_matcher import (
        GraphMatcher,
        TFGraphBuilder
    )

    from snpe.converters.tensorflow.converter import TopologyResolver
    from snpe.converters.tensorflow.converter import ConverterContext
    from snpe.converters.tensorflow.converter import DlcConverter

except Exception as e:
    from converters.tensorflow.loader import ModelLoader
    from collections import OrderedDict
    import snpe

    import converters.code_to_message as code_to_message
    import converters.tensorflow.layers as layers
    from converters.tensorflow.layers.ignored_patterns import IgnoredLayersResolver
    from converters.tensorflow.common import InputLayerDescriptor
    from converters.tensorflow.util import (
        ConverterError,
        GraphHelper,
        uniques
    )
    from converters.tensorflow.graph_matcher import (
        GraphMatcher,
        TFGraphBuilder
    )

    from converters.tensorflow.converter import TopologyResolver
    from converters.tensorflow.converter import ConverterContext
    from converters.tensorflow.converter import DlcConverter

class DlcConverterForNetron(DlcConverter):

    def __init__(self, model, strict_node_resolution, mapping_file):
        """
        :type model: converters.tensorflow.loader.Model
        :type strict_node_resolution: bool
        mapping_file: locate in the same dir as pb file, and has  the name that combine pb name and suffix _mapping.json
        """
        super(DlcConverterForNetron, self).__init__(model, strict_node_resolution)
        self._mapping_file = mapping_file

    def convert(self, dlc_output_path, model_version, converter_command):
        """
        :type dlc_output_path: str
        :type model_version: str
        :type converter_command: str
        :rtype: None
        """
        self._graph_helper = GraphHelper(self._model.session, self._model, self._ops)
        self._topology_resolver = TopologyResolver()
        self._context = ConverterContext(self._model, snpe.modeltools.Model(), self._graph_helper,
                                         self._topology_resolver, self._logger)
        self._logger.info(code_to_message.get_progress_message('INFO_ALL_BUILDING_NETWORK'))
        self._context.model.add_validation_targets(self._context.model.get_validation_targets())
        self._convert_input_layers()
        self._convert_layers()
		
		# It should be finish if we just want the mapping relationship
		# TO-DO: add more arguments so that user can choose continue or not
		
        #self._set_model_version(model_version)
        #self._context.model.set_converter_command(converter_command)
        #self._context.model.save(dlc_output_path)


    def _convert_layers(self):
        """
        :rtype: None
        """
        graph_ops = list(self._ops)
        descriptors = self._resolve_descriptors_from_nodes(graph_ops)
        descriptors = self._resolve_hierarchical_resolution_conflicts(descriptors)

        self._topology_resolver.resolve_topology(self._input_descriptors + descriptors)
        print('manual debug')
        self._generateMappingFile(self._input_descriptors + descriptors, graph_ops)
        # descriptors = self._topology_resolver.sort_descriptors_in_execution_order(descriptors, self._input_descriptors)
        # descriptors = self._filter_disconnected_descriptors(descriptors)
        # self._transform_descriptors(descriptors)

        # self._topology_resolver.resolve_topology(self._input_descriptors + descriptors)
        # descriptors = [d for d in descriptors if not d.is_ignored]

        # if self._strict_node_resolution:
        #     self._assert_all_ops_consumed(descriptors, graph_ops)

    def _generateMappingFile(self, descriptors, ops):
        mapping_dict = dict()
        recognized_nodes = []
        for d in descriptors:
            ns = [op.name for op in d.child_ops]
            mapping_dict[d.layer_name] = ns
            recognized_nodes.extend(ns)

        unknown_nodes = []
        for node in ops:
            node_name = node.name
            if node_name not in recognized_nodes:
                unknown_nodes.append(node_name)
        mapping_dict['UNKNOWN'] = unknown_nodes

        import json
        with open(self._mapping_file, 'w') as fp:
            json.dump(mapping_dict, fp)
        # self._create_layers(descriptors)


def __setup_logger(verbose):
    formatter = '%(asctime)s - %(lineno)d - %(levelname)s - %(message)s'
    formatter = logging.Formatter(formatter)
    lvl = logging.WARN
    if verbose:
        lvl = logging.DEBUG
    stream_handler = logging.StreamHandler()
    stream_handler.setLevel(lvl)
    stream_handler.setFormatter(formatter)

    logger = logging.getLogger()
    logger.setLevel(lvl)
    logger.addHandler(stream_handler)
    return logger


def __parse_args():

    _try_add_input_dim()
    _try_add_output_node()

    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="Script to convert a TensorFlow graph into a DLC file.")
    parser._action_groups.pop()

    required = parser.add_argument_group('required arguments')
    required.add_argument('--graph', type=str, required=True,
                          help='Path to TensorFlow graph def (.pb saved as binary) or graph meta (.meta) file.')
    required.add_argument('-i', '--input_dim', nargs=2, action='append', required=True, metavar=('INPUT_NAME','INPUT_DIM'),
                          help='The names and dimensions of the network input layers specified in the format "input_name" comma-separated-dimensions, for example: "data" 1,224,224,3. Note that the quotes should always be included in order to handle special characters, spaces, etc. For multiple inputs specify multiple --input_dim on the command line like: --input_dim "data1" 1,224,224,3 --input_dim "data2" 1,50,100,3.')
    required.add_argument('--out_node', type=str, required=True, action='append',
                          help='Name of the graph\'s output node.')


    optional = parser.add_argument_group('optional arguments')

    optional.add_argument('--dlc', type=str,
                          help='Path to DLC file to be generated.')
    # Note that setting the model version is not supported in the 0.12.0 version of the SNPE-R model tools.
    # This appears to be QCT specific code, so I'm leaving the code in but commenting out the actual set in converter.py
    # We can sort out whether SNPE-R should support this post 0.12.0
    optional.add_argument('--model_version', type=str,
                        help='User-defined ASCII string to identify the model, only first 64 bytes will be stored')
    optional.add_argument('--in_type', type=str, choices=['default', 'image'], action='append',
                          help='Type of data expected by input layer. Type is default if not specified.')
    optional.add_argument("--allow_unconsumed_nodes", action="store_true",
                          help="Uses a relaxed graph node to layer mapping algorithm which may not use "
                               "all graph nodes during conversion while retaining structural integrity.",
                          default=False)
    optional.add_argument("--verbose", dest="verbose", action="store_true",
                          help="Verbose printing", default=False)

    args = parser.parse_args()

    if args.dlc is None:
        filename, _ = os.path.splitext(os.path.realpath(args.graph))
        args.dlc = filename + ".dlc"

    return args

def _try_add_output_node():
    if _argument_exist('--out_node'):
        return

    file_name = _get_model_name()
    if not file_name:
        return
    def node_name_from_input(input):
        input_partial = input.split(':')
        input_name = input_partial[0]
        if input_name.startswith('^'):
            input_name = input_name.lstrip('^')
        return input_name

    with tf.gfile.GFile(file_name, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        g_in = tf.import_graph_def(graph_def)

    output_map = dict()
    has_output = set()
    for node in graph_def.node:
        for input in node.input:
            input_name = node_name_from_input(input)
            has_output.add(input_name)
            output_map[input_name] = node

    properly_output = []
    unlikely_output_types = ['Const', 'Assign', 'NoOp', 'Placeholder']
    for node in graph_def.node:
        node_name = node.name
        if node_name not in has_output and node_name not in unlikely_output_types:
            properly_output.append(node)

    for node in properly_output:
        sys.argv.append('--out_node')
        sys.argv.append(node.name)


# If user didn't provide --input_dim/-i argument, try to retrieve input nodes and dimension
# from the model file provided
def _try_add_input_dim():
    # To see if user has already provide --input_dim/-i argument
    if _argument_exist('--input_dim') or _argument_exist('-i'):
        return

    file_name = _get_model_name()
    if not file_name:
        return

    # Retrieve input node's name and dim from .pb file
    with tf.gfile.GFile(file_name, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        g_in = tf.import_graph_def(graph_def)

    input_nodes = []
    for node in graph_def.node:
        if 'Placeholder' == node.op:
            name = node.name
            dim = '1,1,1,1'
            if node.attr.get('shape') is not None:
                dim_str = node.attr.get('shape').shape.dim
                ds = []
                for d in dim_str:
                    ds.append(str(d.size))
                dim = ','.join(ds)
            input_nodes.append((name, dim))

    # Add all input node info into command-line args
    for name, dim in input_nodes:
        dim = dim.replace('-1', '1')
        sys.argv.append('-i')
        sys.argv.append(name)
        sys.argv.append(dim)


def _get_model_name():
    file_name = None
    try:
        graph_arg_index = sys.argv.index('--graph')
        file_name = sys.argv[graph_arg_index + 1]
    except Exception:
        pass
    return file_name


def _argument_exist(arg):
    if arg in sys.argv:
        return True
    return False


def sanitize_converter_command(args):
    sanitized_args = []
    for k, v in list(vars(args).items()):
        if k in ['graph', 'd', 'dlc']:
            continue
        sanitized_args.append('{}={}'.format(k, v))

    return "{} {}".format(sys.argv[0].split('/')[-1], ' '.join(sanitized_args))


def main():
    _try_add_input_dim()
    _try_add_output_node()
    args = __parse_args()
    logger = __setup_logger(args.verbose)
    session = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))
    with session.as_default():
        try:
            (in_nodes, in_dims) = list(zip(*args.input_dim))
            loader = ModelLoader(logger)
            model = loader.load(args.graph, in_nodes, in_dims, args.in_type, args.out_node, session)

            mapping_file = args.dlc.rstrip('.dlc') + '_mapping.json'
            converter_command = sanitize_converter_command(args)
            converter = DlcConverterForNetron(model, not args.allow_unconsumed_nodes, mapping_file)
            converter.convert(args.dlc, args.model_version, converter_command)
            logger.info("Model conversion completed!")
        except ConverterError as e:
            logger.error("Conversion failed: {}".format(str(e)))
            sys.exit(1)
        except Exception as e:
            logger.error("Encountered Error: {}".format(str(e)))
            traceback.print_exc()
            sys.exit(1)


if __name__ == '__main__':
    main()

